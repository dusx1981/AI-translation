# 标记

- 在大模型训练中，“标记”（tokenization）是将输入文本分割成较小的单元（称为“标记”或“tokens”）的过程。
- 这些标记是模型理解和处理语言的基本单位。
- 标记化是自然语言处理（NLP）模型中一个关键步骤，决定了模型如何接收和理解输入数据。

## 标记化的原理
    标记化的基本原理是将文本数据转换为模型可以理解的格式。

- 词级别标记化（Word-level Tokenization）：
    这种方法将句子中的每个单词作为一个标记。这是最直观的一种标记化方式，适用于较简单的模型和任务。
    例如，句子“我喜欢学习深度学习”会被标记化为["我", "喜欢", "学习", "深度", "学习"]。

- 子词级别标记化（Subword-level Tokenization）：
    子词级别标记化将单词分解为更小的单元，如前缀、后缀或其他常见子串。这种方法有助于处理未登录词（即模型训练时未见过的词）。
    常见的子词标记化方法包括 BPE（Byte Pair Encoding）和 WordPiece。
    例如，句子“我喜欢学习深度学习”可能会被标记化为["我", "喜欢", "学习", "深", "度", "学", "习"]。

- 字符级别标记化（Character-level Tokenization）：
    这种方法将每个字符视为一个标记。它能够完全避免未登录词的问题，但会生成非常长的标记序列，增加了模型的复杂性。
    例如，句子“我喜欢学习深度学习”会被标记化为["我", "喜", "欢", "学", "习", "深", "度", "学", "习"]。

- 字节级别标记化（Byte-level Tokenization）：
    字节级别标记化是另一种处理多语言文本的方法，特别是在处理非拉丁字符时。它将文本转为其字节表示，这样即使是未登录词也能被处理。

## 标记化的过程
1. 文本预处理：首先对原始文本进行预处理，包括去除标点符号、转换大小写（如果需要）等。
2. 词汇表构建：基于训练数据，构建一个包含常见标记的词汇表。词汇表通常会限制在一定大小，以减少模型的复杂度。
3. 文本分割：将输入文本按照词汇表中的标记进行分割。如果使用子词标记化方法，则需要将未登录词拆分成多个子词标记。
4. 映射为ID：每个标记在词汇表中有一个唯一的ID，标记化的结果就是将这些标记转换为对应的ID序列。
5. 处理特殊标记：一些模型可能会加入特殊标记，如句子起始标记[CLS]，句子结束标记[SEP]，填充标记[PAD]，以及未知标记[UNK]等。

## 举例说明
- 原始句子："猫在跑"
    - 词级别标记化：["猫", "在", "跑"]
    - 子词级别标记化（假设使用 BPE）：["猫", "在", "跑"] 或者 ["猫", "在", "跑"]
    - 字符级别标记化：["猫", "在", "跑"]
    - 映射为ID（假设词汇表如下）：{"猫": 1, "在": 2, "跑": 3} -> [1, 2, 3]
经过标记化处理后，模型会处理这些ID序列，而不是直接处理原始的文本字符串。

## 标记化的挑战
1. 词汇表大小：词汇表太大可能导致模型复杂度增加，训练和推理时间变长；而词汇表太小可能无法充分捕捉语言的多样性。
2. 未登录词：如何有效处理未登录词（特别是在开放域任务中）是一个挑战。***子词级别标记化*** 和 ***字符级别标记化*** 是常用的解决方案。
3. ***多语言支持：对于支持多语言的模型，设计合适的标记化方法（如字节级别标记化）尤为重要。***